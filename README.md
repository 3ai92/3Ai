# 3Ai - Intelligent Document Processing Platform

A full-stack web application that combines OCR (Optical Character Recognition) technology with interactive document annotation capabilities. The platform allows users to upload images or documents, automatically extract text using PaddleOCR, and create interactive form overlays for data extraction and annotation.

## ğŸš€ Features

- **Advanced OCR Processing**: Powered by PaddleOCR with RapidOCR integration for accurate text recognition
- **Interactive Document Viewer**: Real-time document annotation with overlay system
- **Form Field Creation**: Dynamic form field placement and data extraction
- **Multi-format Support**: Handles images and documents with visualization capabilities
- **Responsive UI**: Modern web interface built with Next.js and Ant Design
- **API Integration**: RESTful API for OCR processing and document management

## ğŸ—ï¸ Architecture

### Backend (`/backend`)
- **FastAPI** server with CORS support
- **PaddleOCR** integration for text extraction
- **OpenCV** for image processing
- **ONNX Runtime** for model inference
- File upload and processing endpoints

### Frontend (`/my-app`)
- **Next.js** React application with TypeScript
- **Ant Design** for UI components
- **Konva.js** for interactive canvas operations
- **PDF.js** for document rendering
- Responsive design with sidebar navigation

## ğŸ› ï¸ Tech Stack

**Backend:**
- Python 3.x
- FastAPI
- PaddleOCR
- OpenCV
- ONNX Runtime
- Uvicorn

**Frontend:**
- Next.js 15
- React 19
- TypeScript
- Ant Design
- Konva.js
- PDF.js

## ğŸ“¦ Installation

### Prerequisites
- Python 3.8+
- Node.js 18+
- npm or yarn

### Backend Setup

```bash
cd backend

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run the server
python3 -m uvicorn app:app --reload
```

### Frontend Setup

```bash
cd my-app

# Install dependencies
npm install

# Run development server
npm run dev
```

## ğŸš€ Usage

### CLI Usage (Backend)
```bash
# Run OCR on an image
python3 -m rapidocr.main -img test.png -vis
```

### Web Interface
1. Start both backend and frontend servers
2. Open your browser to `http://localhost:3000`
3. Upload an image or document
4. View OCR results and create interactive annotations
5. Export processed data in JSON or Markdown format

### API Endpoints

- `POST /ocr` - Process image with OCR
- `POST /upload` - Upload and process document
- `GET /` - Serve web interface

## ğŸ“ Project Structure

```
3Ai/
â”œâ”€â”€ backend/                 # FastAPI backend
â”‚   â”œâ”€â”€ app.py              # Main FastAPI application
â”‚   â”œâ”€â”€ rapidocr/           # OCR processing modules
â”‚   â”œâ”€â”€ output/             # Generated files
â”‚   â””â”€â”€ web/                # Static web files
â”œâ”€â”€ my-app/                 # Next.js frontend
â”‚   â”œâ”€â”€ components/         # React components
â”‚   â”œâ”€â”€ pages/              # Next.js pages
â”‚   â”œâ”€â”€ utils/              # Utility functions
â”‚   â””â”€â”€ types/              # TypeScript definitions
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

The application uses default OCR models from PaddleOCR. Models are automatically downloaded on first run.

## ğŸ“„ License

This project is based on [RapidAI/PaddleOCRModelConvert](https://github.com/RapidAI/PaddleOCRModelConvert).

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## ğŸ“ Support

For issues and questions, please open an issue on GitHub.

---

**Tags:** `ocr`, `document-processing`, `paddleocr`, `fastapi`, `nextjs`, `react`, `typescript`, `text-extraction`, `document-annotation`, `form-builder`, `rapidocr`, `computer-vision`, `ai`, `machine-learning`
